#!/usr/bin/env python3
"""
æ”¿åºœæ–°èå…¬å ±ç²å–å™¨ (Python ç‰ˆæœ¬)
"""

import os
import sys
import re
import time
from datetime import datetime
from typing import List, Dict, Optional
import feedparser
import requests
from bs4 import BeautifulSoup
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šé‡
load_dotenv()

# åˆå§‹åŒ– Firebase
if not firebase_admin._apps:
    # å˜—è©¦ä½¿ç”¨ç’°å¢ƒè®Šé‡ä¸­çš„æœå‹™å¸³æˆ¶
    cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
    if cred_path and os.path.exists(cred_path):
        cred = credentials.Certificate(cred_path)
        firebase_admin.initialize_app(cred)
    else:
        # å˜—è©¦ä½¿ç”¨é …ç›®æ ¹ç›®éŒ„çš„æœå‹™å¸³æˆ¶æ–‡ä»¶
        default_cred_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'service-account-key.json')
        if os.path.exists(default_cred_path):
            cred = credentials.Certificate(default_cred_path)
            firebase_admin.initialize_app(cred)
        else:
            try:
                # ä½¿ç”¨é»˜èªæ†‘è­‰ï¼ˆé©ç”¨æ–¼ Cloud Functions æˆ–å·²è¨­ç½®çš„ç’°å¢ƒï¼‰
                firebase_admin.initialize_app()
            except Exception as e:
                print("âŒ Firebase åˆå§‹åŒ–å¤±æ•—ï¼")
                print("\nè«‹è¨­ç½® Firebase æ†‘è­‰ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š")
                print("1. ä¸‹è¼‰æœå‹™å¸³æˆ¶å¯†é‘°æ–‡ä»¶ï¼ˆJSONï¼‰")
                print("2. è¨­ç½®ç’°å¢ƒè®Šé‡ï¼š")
                print("   export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json")
                print("   æˆ–å°‡æ–‡ä»¶æ”¾åœ¨é …ç›®æ ¹ç›®éŒ„ä¸¦å‘½åç‚º 'service-account-key.json'")
                print("\nè©³ç´°èªªæ˜ï¼šhttps://cloud.google.com/docs/authentication/external/set-up-adc")
                raise

db = firestore.client()

# ç«ç½ç›¸é—œé—œéµè©ï¼ˆæ ¸å¿ƒé—œéµè©ï¼Œå¿…é ˆåŒ…å«ï¼‰
CORE_FIRE_KEYWORDS = [
    "ç«",
    "ç«è­¦",
    "ç«ç½",
    "ç«ç½äº‹æ•…",
    "ç«ç½ç¾å ´",
    "å®ç¦è‹‘",  # ç‰¹å®šåœ°é»
]

# è¼”åŠ©é—œéµè©
SUPPORTING_KEYWORDS = [
    "å¤§åŸ”",
    "å®ç¦",
    "åº‡è­·ä¸­å¿ƒ",
    "è‡¨æ™‚åº‡è­·",
    "ç–æ•£",
    "æ¶ˆé˜²",
    "æ•‘æ´",
    "ç·Šæ€¥",
    "æ’¤é›¢",
]


def is_fire_related(text: str) -> bool:
    """æª¢æŸ¥æ–‡æœ¬æ˜¯å¦èˆ‡ç«ç½ç›¸é—œ"""
    if not text or not text.strip():
        return False
    
    lower_text = text.lower()
    
    # å¿…é ˆåŒ…å«è‡³å°‘ä¸€å€‹æ ¸å¿ƒé—œéµè©
    has_core_keyword = any(
        keyword.lower() in lower_text for keyword in CORE_FIRE_KEYWORDS
    )
    
    if has_core_keyword:
        return True
    
    # å¦‚æœæ²’æœ‰æ ¸å¿ƒé—œéµè©ï¼Œæª¢æŸ¥æ˜¯å¦åŒæ™‚åŒ…å«å¤šå€‹è¼”åŠ©é—œéµè©
    supporting_count = sum(
        1 for keyword in SUPPORTING_KEYWORDS
        if keyword.lower() in lower_text
    )
    
    # å¦‚æœåŒ…å« 2 å€‹æˆ–ä»¥ä¸Šçš„è¼”åŠ©é—œéµè©ï¼Œä¸”åŒ…å«"å¤§åŸ”"æˆ–"å®ç¦"ï¼Œå‰‡èªç‚ºç›¸é—œ
    if supporting_count >= 2:
        return "å¤§åŸ”" in lower_text or "å®ç¦" in lower_text
    
    return False


def parse_rss_date(pub_date) -> str:
    """è§£æ RSS pubDate ç‚ºä¸­æ–‡æ—¥æœŸæ ¼å¼"""
    try:
        # feedparser æœƒè‡ªå‹•è§£ææ—¥æœŸç‚º time.struct_time
        if hasattr(pub_date, 'tm_year'):
            return f"{pub_date.tm_year}å¹´{pub_date.tm_mon}æœˆ{pub_date.tm_mday}æ—¥"
        elif isinstance(pub_date, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå˜—è©¦è§£æ
            dt = datetime.strptime(pub_date[:19], "%Y-%m-%dT%H:%M:%S")
            return f"{dt.year}å¹´{dt.month}æœˆ{dt.day}æ—¥"
    except:
        pass
    return datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")


def clean_html(html: str) -> str:
    """æ¸…ç† HTML æ¨™ç±¤å’Œå¯¦é«”"""
    if not html:
        return ""
    
    soup = BeautifulSoup(html, 'html.parser')
    text = soup.get_text()
    
    # æ¸…ç†å¤šé¤˜ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def fetch_gov_news() -> List[Dict[str, str]]:
    """ç²å–æ”¿åºœæ–°èå…¬å ±ï¼ˆä½¿ç”¨ RSS Feedï¼‰"""
    rss_url = "https://www.info.gov.hk/gia/rss/general_zh.xml"
    
    try:
        print(f"ğŸ“° æ­£åœ¨å¾ RSS Feed ç²å–æ”¿åºœæ–°è: {rss_url}")
        
        feed = feedparser.parse(rss_url)
        
        if feed.bozo:
            print(f"âš ï¸  RSS è§£æè­¦å‘Š: {feed.bozo_exception}")
        
        news_items = []
        
        for entry in feed.entries:
            title = entry.get('title', '').strip()
            link = entry.get('link', '').strip()
            description = entry.get('description', '').strip()
            pub_date = entry.get('published', '')
            
            if not title or not link:
                continue
            
            # æª¢æŸ¥æ˜¯å¦èˆ‡ç«ç½ç›¸é—œ
            title_related = is_fire_related(title)
            desc_related = is_fire_related(description)
            
            if title_related or desc_related:
                # ä½¿ç”¨ published_parsedï¼ˆfeedparser è§£æå¾Œçš„æ—¥æœŸï¼‰æˆ– pub_date
                date_obj = entry.get('published_parsed') or pub_date
                date_str = parse_rss_date(date_obj) if date_obj else datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
                news_items.append({
                    'title': title,
                    'url': link,
                    'date': date_str,
                    'description': clean_html(description)
                })
                print(f"âœ… æ‰¾åˆ°ç›¸é—œæ–°è: {title}")
            else:
                print(f"â­ï¸  è·³éä¸ç›¸é—œæ–°è: {title}")
        
        print(f"âœ… å¾ RSS Feed æ‰¾åˆ° {len(news_items)} æ¢ç›¸é—œæ–°è\n")
        return news_items
        
    except Exception as e:
        print(f"âŒ ç²å– RSS Feed æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        raise


def fetch_news_content(url: str) -> str:
    """ç²å–æ–°èè©³ç´°å…§å®¹"""
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # å˜—è©¦å¤šç¨®å¯èƒ½çš„å…§å®¹é¸æ“‡å™¨
        content_selectors = [
            '#pressrelease',
            '.pressrelease',
            '#content',
            '.content',
            'article',
            'main'
        ]
        
        content = ""
        for selector in content_selectors:
            element = soup.select_one(selector)
            if element:
                content = element.get_text().strip()
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®šå®¹å™¨ï¼Œå˜—è©¦ç²å–æ‰€æœ‰æ®µè½
        if not content:
            paragraphs = soup.find_all('p')
            content = '\n\n'.join([
                p.get_text().strip() for p in paragraphs
                if len(p.get_text().strip()) > 20
            ])
        
        return content.strip() or "ç„¡æ³•ç²å–æ–°èå…§å®¹"
        
    except Exception as e:
        print(f"ç²å–æ–°èå…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤ ({url}): {str(e)}")
        return "ç„¡æ³•ç²å–æ–°èå…§å®¹"


def announcement_exists(title: str) -> bool:
    """æª¢æŸ¥å…¬å‘Šæ˜¯å¦å·²å­˜åœ¨"""
    try:
        announcements_ref = db.collection('announcements')
        query = announcements_ref.where('title', '==', title).limit(1)
        docs = query.stream()
        return len(list(docs)) > 0
    except Exception as e:
        print(f"æª¢æŸ¥å…¬å‘Šæ˜¯å¦å­˜åœ¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return False


def add_announcement(news: Dict[str, str]) -> bool:
    """æ·»åŠ å…¬å‘Šåˆ° Firestore"""
    try:
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if announcement_exists(news['title']):
            print(f"è·³éå·²å­˜åœ¨çš„å…¬å‘Š: {news['title']}")
            return False
        
        # ä½¿ç”¨ description ä½œç‚ºå…§å®¹ï¼Œå¦‚æœæ²’æœ‰å‰‡ç²å–å®Œæ•´å…§å®¹
        content = news.get('description') or news.get('content', '')
        if not content:
            print(f"æ­£åœ¨ç²å–æ–°èå…§å®¹: {news['title']}")
            content = fetch_news_content(news['url'])
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºç·Šæ€¥
        is_urgent = is_fire_related(news['title']) and (
            'ç·Šæ€¥' in news['title'] or
            'ç«è­¦' in news['title'] or
            'ç«ç½' in news['title'] or
            'ç·Šæ€¥' in content or
            'æ’¤é›¢' in content
        )
        
        # è¨­ç½®æ¨™ç±¤
        tag = 'urgent' if is_urgent else 'gov'
        
        # è§£ææ—¥æœŸ
        try:
            date_match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', news['date'])
            if date_match:
                year, month, day = map(int, date_match.groups())
                timestamp = datetime(year, month, day)
            else:
                timestamp = firestore.SERVER_TIMESTAMP
        except:
            timestamp = firestore.SERVER_TIMESTAMP
        
        announcement = {
            'title': news['title'],
            'content': content,
            'source': 'é¦™æ¸¯æ”¿åºœæ–°èå…¬å ±',
            'url': news['url'],
            'isUrgent': is_urgent,
            'tag': tag,
            'timestamp': timestamp
        }
        
        db.collection('announcements').add(announcement)
        print(f"âœ… å·²æ·»åŠ å…¬å‘Š: {news['title']}")
        return True
        
    except Exception as e:
        print(f"æ·»åŠ å…¬å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤ ({news['title']}): {str(e)}")
        return False


def fetch_and_add_gov_news():
    """ä¸»å‡½æ•¸ï¼šç²å–ä¸¦æ·»åŠ æ–°è"""
    try:
        print("ğŸ“° é–‹å§‹ç²å–æ”¿åºœæ–°èå…¬å ±...")
        
        # ç²å–æ–°è
        news_list = fetch_gov_news()
        
        if not news_list:
            print("â„¹ï¸  æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„æ–°è")
            return {
                'success': True,
                'added': 0,
                'total': 0,
                'message': 'æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„æ–°è'
            }
        
        print(f"ğŸ“ é–‹å§‹è™•ç† {len(news_list)} æ¢æ–°è...\n")
        
        added_count = 0
        for news in news_list:
            if add_announcement(news):
                added_count += 1
            # æ·»åŠ å»¶é²é¿å…è«‹æ±‚éå¿«
            time.sleep(1)
        
        message = f"è™•ç†å®Œæˆ: æ–°å¢ {added_count} æ¢å…¬å‘Šï¼Œå…±è™•ç† {len(news_list)} æ¢æ–°è"
        print(f"âœ… {message}")
        
        return {
            'success': True,
            'added': added_count,
            'total': len(news_list),
            'message': message
        }
        
    except Exception as e:
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {str(e)}")
        raise


if __name__ == '__main__':
    try:
        result = fetch_and_add_gov_news()
        print(f"\nåŸ·è¡Œå®Œæˆ: {result['message']}")
        sys.exit(0)
    except Exception as e:
        print(f"\nåŸ·è¡Œå¤±æ•—: {str(e)}")
        sys.exit(1)

